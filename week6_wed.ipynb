{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=100, n_jobs=1,\n",
       "       penalty='none', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Imports##\n",
    "__author__ = 'bdyetton'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Load and prepare data\n",
    "all_charts = pd.read_csv('BillboardLyricData.txt', sep='\\t', encoding='utf-8')\n",
    "all_charts = all_charts.dropna() ## Remove missing data\n",
    "\n",
    "class_mapping = {label:idx for idx,label in enumerate(np.unique(all_charts.chart))}\n",
    "y_raw = all_charts.chart.map(class_mapping)\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2,max_features=1000,stop_words='english')                              \n",
    "vectorizer.fit(all_charts.lyrics) #Creates the dictionary to convert lyrics to counts\n",
    "word_vector = vectorizer.transform(all_charts.lyrics) #Does actual conversion\n",
    "X_raw = word_vector.todense()\n",
    "\n",
    "#Split of test set, and set aside (dont touch until after we have found the best hyperparameters)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=0.3)\n",
    "\n",
    "model_2 = SGDClassifier(loss='log', n_iter=100, penalty='none')\n",
    "model_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Genre is hot-holiday-songs\n",
      "Ten most predicitive words are:\n",
      " [['doo' '-140.0']\n",
      " ['ooh' '-110.0']\n",
      " ['snow' '102.0']\n",
      " ['christmas' '92.0']\n",
      " ['nah' '-85.0']\n",
      " ['really' '-70.0']\n",
      " ['santa' '69.0']\n",
      " ['feel' '-66.0']\n",
      " ['hey' '-59.0']\n",
      " ['love' '-58.0']]\n",
      "\n",
      "Genre is christian-songs\n",
      "Ten most predicitive words are:\n",
      " [['cruisin' '106.0']\n",
      " ['wicked' '-106.0']\n",
      " ['family' '95.0']\n",
      " ['sorry' '-82.0']\n",
      " ['shit' '-78.0']\n",
      " ['drank' '-77.0']\n",
      " ['grace' '76.0']\n",
      " ['human' '-76.0']\n",
      " ['friends' '73.0']\n",
      " ['lord' '72.0']]\n",
      "\n",
      "Genre is country-songs\n",
      "Ten most predicitive words are:\n",
      " [['fame' '-175.0']\n",
      " ['ayy' '-174.0']\n",
      " ['doo' '-157.0']\n",
      " ['nah' '-145.0']\n",
      " ['lovin' '-127.0']\n",
      " ['wow' '-96.0']\n",
      " ['la' '-85.0']\n",
      " ['nigga' '-83.0']\n",
      " ['live' '-82.0']\n",
      " ['ooh' '-81.0']]\n",
      "\n",
      "Genre is rock-songs\n",
      "Ten most predicitive words are:\n",
      " [['blow' '-170.0']\n",
      " ['fame' '148.0']\n",
      " ['bun' '-119.0']\n",
      " ['ayo' '112.0']\n",
      " ['mum' '-100.0']\n",
      " ['pipe' '-97.0']\n",
      " ['family' '-85.0']\n",
      " ['rebel' '84.0']\n",
      " ['singing' '-79.0']\n",
      " ['ey' '-75.0']]\n",
      "\n",
      "Genre is pop-songs\n",
      "Ten most predicitive words are:\n",
      " [['bun' '-246.0']\n",
      " ['blow' '-196.0']\n",
      " ['wicked' '-175.0']\n",
      " ['ayy' '-123.0']\n",
      " ['light' '-119.0']\n",
      " ['lotta' '-117.0']\n",
      " ['la' '-115.0']\n",
      " ['ba' '-104.0']\n",
      " ['zero' '104.0']\n",
      " ['thought' '101.0']]\n",
      "\n",
      "Genre is r-b-hip-hop-songs\n",
      "Ten most predicitive words are:\n",
      " [['dope' '320.0']\n",
      " ['nigga' '183.0']\n",
      " ['wicked' '170.0']\n",
      " ['bun' '-154.0']\n",
      " ['ayy' '148.0']\n",
      " ['pipe' '147.0']\n",
      " ['light' '-132.0']\n",
      " ['hey' '-131.0']\n",
      " ['run' '-119.0']\n",
      " ['ooh' '-111.0']]\n",
      "\n",
      "Genre is dance-electronic-songs\n",
      "Ten most predicitive words are:\n",
      " [['boom' '259.0']\n",
      " ['mum' '198.0']\n",
      " ['gyal' '119.0']\n",
      " ['fallin' '-118.0']\n",
      " ['lotta' '-98.0']\n",
      " ['freak' '90.0']\n",
      " ['dog' '-85.0']\n",
      " ['man' '-84.0']\n",
      " ['talking' '-82.0']\n",
      " ['roof' '-82.0']]\n"
     ]
    }
   ],
   "source": [
    "## Extract weights:\n",
    "coef_weights = model_2.coef_\n",
    "\n",
    "#We dont care if the presence or the absence of this word is predictive\n",
    "absolute_coef_weights = np.absolute(coef_weights)\n",
    "\n",
    "## Find index of higest weights (-ve because we want highest to lowest)\n",
    "absolute_coef_idx_sorted = np.argsort(-absolute_coef_weights, axis=1)\n",
    "\n",
    "## Slice off the array after the first 10 to give the index of the highest 10 weights\n",
    "ten_highest_idxs = absolute_coef_idx_sorted[:, :10]\n",
    "\n",
    "## Get the words we used as features. \n",
    "feature_words = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "## Create map from label_ints to label_strings\n",
    "inv_class_mapping = {v: k for k, v in class_mapping.items()}\n",
    "\n",
    "##create a for loop that will run through each row to pull the words that correspond with the argsort place in ten_most_words\n",
    "for label_int in y_raw.unique():\n",
    "    print('\\nGenre is',inv_class_mapping[label_int])\n",
    "    row = ten_highest_idxs[label_int]\n",
    "    coefs = coef_weights[label_int,row]\n",
    "    to_print = np.vstack([feature_words[row],np.round(coefs)])\n",
    "    print('Ten most predicitive words are:\\n', to_print.transpose())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
